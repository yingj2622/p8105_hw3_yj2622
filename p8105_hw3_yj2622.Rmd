---
title: "Homework 3"
author: "Ying Jin"
date: "2020/10/6"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot_cpntinuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Load the dataset

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are user/ order variables -- user ID, order ID, order day and order hour. There are also item variables -- name, aisle, department, and some numeric codes.


How many aisles, and which are most products from?

```{r}
instacart %>% 
  count(aisle) %>%
  nrow()
  
instacart %>% 
  count(aisle) %>%
  arrange(desc(n))
```

There are 134 aisles and most products come from fresh vegetables.

Let's make a plot

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = forcats::fct_reorder(aisle,n)
  ) %>% 
  ggplot(aes(x = aisle, y =n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = .5,hjust = 1))
```

Three most popular items in three aisles

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples vs. Ice Cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarise(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```

## Problem 2

First, load the accelerometer dataset and tidy it.

```{r load_tidy_accel, warning = FALSE, message= FALSE}
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "n_activ"
  ) %>% 
  mutate(
    weekday_vs_weekend = case_when(
      day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday")~"weekday",
      day %in% c("Saturday","Sunday")~"weekend"
    ),
    day = factor(day),
    day = fct_relevel(day, c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
  )

```

The steps I took to wrangle the dataset include:

* clean the column names;

* change the dataset from wide format into long format;

* create a new column named `weekday_vs_weekend` to indicate whether a certain day is a weekday or a weekend;

* change the `day` variable into factor and relevel it.

The resulting dataset contains information about everyday "activity counts" in each commonly one-minute intervals of a 63 year-old male diagnosed with CHF. And the time range is five weeks. 

* It contains `r nrow(accel_df)` rows and `r ncol(accel_df)` variables.

* The dataset provides five-week observations on "activity counts" of a man. The counting starts at the midnight of each day and "activity counts" in each observations in each days are given. Also, information about which week a certain day belongs to, day of the week and whether that day is a weekday or weekend can be obtained.

Then I aggregate across minutes to create a total activity variable for each day and create a table.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(
    total_activ = sum(n_activ)
      ) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activ
  ) %>% 
  knitr::kable()
```


